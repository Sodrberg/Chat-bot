21:04:41,205 graphrag.index.cli INFO Logging enabled at graphrager/output/20240910-210441/reports/indexing-engine.log
21:04:41,208 graphrag.index.cli INFO Starting pipeline run for: 20240910-210441, dryrun=False
21:04:41,209 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "llama-3.1-8b-instant",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://api.groq.com/openai/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 20000,
        "requests_per_minute": 30,
        "max_retries": 3,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "graphrager",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama-3.1-8b-instant",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.groq.com/openai/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 30,
            "max_retries": 3,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama-3.1-8b-instant",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.groq.com/openai/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 30,
            "max_retries": 3,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama-3.1-8b-instant",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.groq.com/openai/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 30,
            "max_retries": 3,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 1000,
        "max_input_length": 4000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama-3.1-8b-instant",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.groq.com/openai/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 30,
            "max_retries": 3,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 5000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 5000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
21:04:41,213 graphrag.index.create_pipeline_config INFO skipping workflows 
21:04:41,213 graphrag.index.run INFO Running pipeline
21:04:41,213 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at graphrager/output/20240910-210441/artifacts
21:04:41,214 graphrag.index.input.load_input INFO loading input from root_dir=input
21:04:41,214 graphrag.index.input.load_input INFO using file storage for input
21:04:41,214 graphrag.index.storage.file_pipeline_storage INFO search graphrager/input for files matching .*\.txt$
21:04:41,215 graphrag.index.input.text INFO found text files from input, found [('snow_white.txt', {})]
21:04:41,217 graphrag.index.input.text INFO Found 1 files, loading 1
21:04:41,221 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
21:04:41,221 graphrag.index.run INFO Final # of rows loaded: 1
21:04:41,362 graphrag.index.run INFO Running workflow: create_base_text_units...
21:04:41,363 graphrag.index.run INFO dependencies for create_base_text_units: []
21:04:41,363 datashaper.workflow.workflow INFO executing verb orderby
21:04:41,364 datashaper.workflow.workflow INFO executing verb zip
21:04:41,365 datashaper.workflow.workflow INFO executing verb aggregate_override
21:04:41,369 datashaper.workflow.workflow INFO executing verb chunk
21:04:41,622 datashaper.workflow.workflow INFO executing verb select
21:04:41,623 datashaper.workflow.workflow INFO executing verb unroll
21:04:41,625 datashaper.workflow.workflow INFO executing verb rename
21:04:41,626 datashaper.workflow.workflow INFO executing verb genid
21:04:41,627 datashaper.workflow.workflow INFO executing verb unzip
21:04:41,629 datashaper.workflow.workflow INFO executing verb copy
21:04:41,629 datashaper.workflow.workflow INFO executing verb filter
21:04:41,644 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
21:04:41,836 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
21:04:41,837 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
21:04:41,838 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
21:04:41,846 datashaper.workflow.workflow INFO executing verb entity_extract
21:04:41,850 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.groq.com/openai/v1
21:04:41,910 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for llama-3.1-8b-instant: TPM=20000, RPM=30
21:04:41,910 graphrag.index.llm.load_llm INFO create concurrency limiter for llama-3.1-8b-instant: 25
21:04:41,943 datashaper.workflow.workflow INFO executing verb merge_graphs
21:04:41,955 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
21:04:42,119 graphrag.index.run INFO Running workflow: create_summarized_entities...
21:04:42,120 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
21:04:42,121 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
21:04:42,128 datashaper.workflow.workflow INFO executing verb summarize_descriptions
21:04:42,693 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5004989498993382. input_tokens=167, output_tokens=81
21:04:42,733 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,735 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48836271499749273. input_tokens=156, output_tokens=98
21:04:42,770 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,773 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5795545530272648. input_tokens=189, output_tokens=78
21:04:42,814 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,815 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6061839020112529. input_tokens=199, output_tokens=28
21:04:42,817 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5646829759934917. input_tokens=169, output_tokens=106
21:04:42,818 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,974 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,976 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:42,977 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,106 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,107 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,108 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,109 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,185 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,189 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,240 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,293 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,631 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,632 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,652 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,728 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,741 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,760 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,889 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:43,909 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:04:44,821 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5995323009556159. input_tokens=181, output_tokens=41
21:04:46,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7206659110961482. input_tokens=162, output_tokens=76
21:04:48,825 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7539518430130556. input_tokens=160, output_tokens=84
21:04:50,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.80437287397217. input_tokens=167, output_tokens=43
21:04:52,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9038810040801764. input_tokens=147, output_tokens=44
21:04:54,831 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8511353279463947. input_tokens=213, output_tokens=91
21:04:56,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8975504400441423. input_tokens=175, output_tokens=20
21:04:58,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8922205290291458. input_tokens=167, output_tokens=113
21:05:00,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9744541089748964. input_tokens=193, output_tokens=55
21:05:02,836 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0011538660619408. input_tokens=214, output_tokens=78
21:05:04,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0129024790367112. input_tokens=165, output_tokens=83
21:05:06,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0955938029801473. input_tokens=193, output_tokens=87
21:05:08,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.390111199929379. input_tokens=162, output_tokens=59
21:05:10,843 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3795451630139723. input_tokens=173, output_tokens=60
21:05:12,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4200058040441945. input_tokens=143, output_tokens=28
21:05:14,846 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.497652810998261. input_tokens=146, output_tokens=31
21:05:16,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4785287419799715. input_tokens=144, output_tokens=191
21:05:18,854 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.513418030925095. input_tokens=176, output_tokens=28
21:05:20,856 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6525931539945304. input_tokens=176, output_tokens=78
21:05:22,857 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7078686809400097. input_tokens=153, output_tokens=69
21:05:22,868 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
21:05:23,44 graphrag.index.run INFO Running workflow: create_base_entity_graph...
21:05:23,45 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
21:05:23,46 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
21:05:23,52 datashaper.workflow.workflow INFO executing verb cluster_graph
21:05:23,88 datashaper.workflow.workflow INFO executing verb select
21:05:23,90 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
21:05:23,239 graphrag.index.run INFO Running workflow: create_final_entities...
21:05:23,239 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
21:05:23,240 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
21:05:23,243 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:23,250 datashaper.workflow.workflow INFO executing verb rename
21:05:23,251 datashaper.workflow.workflow INFO executing verb select
21:05:23,252 datashaper.workflow.workflow INFO executing verb dedupe
21:05:23,256 datashaper.workflow.workflow INFO executing verb rename
21:05:23,257 datashaper.workflow.workflow INFO executing verb filter
21:05:23,264 datashaper.workflow.workflow INFO executing verb text_split
21:05:23,267 datashaper.workflow.workflow INFO executing verb drop
21:05:23,268 datashaper.workflow.workflow INFO executing verb merge
21:05:23,287 datashaper.workflow.workflow INFO executing verb text_embed
21:05:23,289 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
21:05:23,339 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
21:05:23,339 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
21:05:23,345 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 55 inputs via 55 snippets using 4 batches. max_batch_size=16, max_tokens=8191
21:05:24,1 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
21:05:24,41 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
21:05:24,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
21:05:24,52 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
21:05:24,240 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900393219664693. input_tokens=135, output_tokens=0
21:05:24,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1850915719987825. input_tokens=347, output_tokens=0
21:05:24,559 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2075677260290831. input_tokens=694, output_tokens=0
21:05:25,578 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.2298033570405096. input_tokens=623, output_tokens=0
21:05:25,602 datashaper.workflow.workflow INFO executing verb drop
21:05:25,603 datashaper.workflow.workflow INFO executing verb filter
21:05:25,609 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
21:05:25,846 graphrag.index.run INFO Running workflow: create_final_nodes...
21:05:25,847 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
21:05:25,847 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
21:05:25,850 datashaper.workflow.workflow INFO executing verb layout_graph
21:05:25,875 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:25,882 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:25,890 datashaper.workflow.workflow INFO executing verb filter
21:05:25,895 datashaper.workflow.workflow INFO executing verb drop
21:05:25,896 datashaper.workflow.workflow INFO executing verb select
21:05:25,897 datashaper.workflow.workflow INFO executing verb rename
21:05:25,898 datashaper.workflow.workflow INFO executing verb convert
21:05:25,909 datashaper.workflow.workflow INFO executing verb join
21:05:25,930 datashaper.workflow.workflow INFO executing verb rename
21:05:25,932 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
21:05:26,103 graphrag.index.run INFO Running workflow: create_final_communities...
21:05:26,103 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
21:05:26,104 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
21:05:26,108 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:26,114 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:26,120 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:26,133 datashaper.workflow.workflow INFO executing verb join
21:05:26,144 datashaper.workflow.workflow INFO executing verb join
21:05:26,153 datashaper.workflow.workflow INFO executing verb concat
21:05:26,154 datashaper.workflow.workflow INFO executing verb filter
21:05:26,162 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:26,167 datashaper.workflow.workflow INFO executing verb join
21:05:26,175 datashaper.workflow.workflow INFO executing verb filter
21:05:26,181 datashaper.workflow.workflow INFO executing verb fill
21:05:26,182 datashaper.workflow.workflow INFO executing verb merge
21:05:26,184 datashaper.workflow.workflow INFO executing verb copy
21:05:26,185 datashaper.workflow.workflow INFO executing verb select
21:05:26,187 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
21:05:26,364 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
21:05:26,365 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
21:05:26,365 graphrag.index.run INFO read table from storage: create_final_entities.parquet
21:05:26,384 datashaper.workflow.workflow INFO executing verb select
21:05:26,385 datashaper.workflow.workflow INFO executing verb unroll
21:05:26,389 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:26,394 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
21:05:26,569 graphrag.index.run INFO Running workflow: create_final_relationships...
21:05:26,570 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
21:05:26,571 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
21:05:26,589 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
21:05:26,594 datashaper.workflow.workflow INFO executing verb unpack_graph
21:05:26,600 datashaper.workflow.workflow INFO executing verb filter
21:05:26,606 datashaper.workflow.workflow INFO executing verb rename
21:05:26,607 datashaper.workflow.workflow INFO executing verb filter
21:05:26,612 datashaper.workflow.workflow INFO executing verb drop
21:05:26,613 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
21:05:26,619 datashaper.workflow.workflow INFO executing verb convert
21:05:26,620 datashaper.workflow.workflow INFO executing verb convert
21:05:26,623 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
21:05:26,809 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
21:05:26,810 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
21:05:26,811 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
21:05:26,819 datashaper.workflow.workflow INFO executing verb select
21:05:26,820 datashaper.workflow.workflow INFO executing verb unroll
21:05:26,824 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:26,827 datashaper.workflow.workflow INFO executing verb select
21:05:26,830 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
21:05:27,8 graphrag.index.run INFO Running workflow: create_final_community_reports...
21:05:27,9 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
21:05:27,9 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
21:05:27,18 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
21:05:27,24 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
21:05:27,27 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
21:05:27,30 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
21:05:27,36 datashaper.workflow.workflow INFO executing verb prepare_community_reports
21:05:27,36 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 55
21:05:27,80 datashaper.workflow.workflow INFO executing verb create_community_reports
21:05:28,958 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:05:28,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.8669419669313356. input_tokens=2756, output_tokens=649
21:05:30,477 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:05:30,480 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.3776391650317237. input_tokens=3038, output_tokens=973
21:05:34,487 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:05:34,490 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.0071972419973463. input_tokens=3248, output_tokens=681
21:05:38,159 httpx INFO HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
21:05:40,162 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.6693411320447922. input_tokens=2024, output_tokens=336
21:05:40,166 datashaper.workflow.workflow INFO executing verb window
21:05:40,169 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
21:05:40,360 graphrag.index.run INFO Running workflow: create_final_text_units...
21:05:40,361 graphrag.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids']
21:05:40,361 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
21:05:40,371 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
21:05:40,377 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
21:05:40,383 datashaper.workflow.workflow INFO executing verb select
21:05:40,384 datashaper.workflow.workflow INFO executing verb rename
21:05:40,384 datashaper.workflow.workflow INFO executing verb join
21:05:40,393 datashaper.workflow.workflow INFO executing verb join
21:05:40,402 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:40,407 datashaper.workflow.workflow INFO executing verb select
21:05:40,409 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
21:05:40,586 graphrag.index.run INFO Running workflow: create_base_documents...
21:05:40,587 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
21:05:40,587 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
21:05:40,594 datashaper.workflow.workflow INFO executing verb unroll
21:05:40,597 datashaper.workflow.workflow INFO executing verb select
21:05:40,598 datashaper.workflow.workflow INFO executing verb rename
21:05:40,599 datashaper.workflow.workflow INFO executing verb join
21:05:40,607 datashaper.workflow.workflow INFO executing verb aggregate_override
21:05:40,610 datashaper.workflow.workflow INFO executing verb join
21:05:40,619 datashaper.workflow.workflow INFO executing verb rename
21:05:40,620 datashaper.workflow.workflow INFO executing verb convert
21:05:40,624 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
21:05:40,796 graphrag.index.run INFO Running workflow: create_final_documents...
21:05:40,797 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
21:05:40,797 graphrag.index.run INFO read table from storage: create_base_documents.parquet
21:05:40,804 datashaper.workflow.workflow INFO executing verb rename
21:05:40,807 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
21:05:40,872 graphrag.index.cli INFO All workflows completed successfully.
